{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0bfef6a-cc35-4760-81fe-4fe8928d5a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import LongformerTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(r\"B:\\project\\chunks\\chunk_2.csv\")\n",
    "essays = df['text'].tolist()\n",
    "\n",
    "# Tokenize using LongformerTokenizer\n",
    "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "tokens = tokenizer(essays, return_tensors='pt', padding=True, truncation=True)\n",
    "x = tokens['input_ids']\n",
    "y = df['generated'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a2c784bb-993d-46d8-997f-a96b991aea1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs size: torch.Size([12180, 4096])\n",
      "Attention Mask size: torch.Size([12180, 4096])\n"
     ]
    }
   ],
   "source": [
    "input_ids_size = tokens['input_ids'].size()\n",
    "attention_mask_size = tokens['attention_mask'].size()\n",
    "print(\"Input IDs size:\", input_ids_size)\n",
    "print(\"Attention Mask size:\", attention_mask_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b5c16f7-5fd2-42c4-b5e0-2f1851497b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 26781\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'tokens' is the result of tokenizer\n",
    "unique_tokens = set(token.item() for seq in tokens['input_ids'] for token in seq)\n",
    "vocabulary_size = len(unique_tokens)\n",
    "\n",
    "print(\"Vocabulary Size:\", vocabulary_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d346a69f-c190-43c5-8fc8-a44e239a13b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Sequence Length: 4096\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'input_ids' is the first element in xtrain\n",
    "max_sequence_length_x = max(len(seq) for seq in xtrain)\n",
    "\n",
    "# Print or use the max_sequence_length_x in your pad_sequences and Embedding layer\n",
    "print(\"Max Sequence Length:\", max_sequence_length_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "519a31e1-3c93-46b0-95d9-7385700484f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "305/305 [==============================] - 735s 2s/step - loss: 0.6760 - accuracy: 0.5955\n",
      "Epoch 2/5\n",
      "305/305 [==============================] - 838s 3s/step - loss: 0.6755 - accuracy: 0.5956\n",
      "Epoch 3/5\n",
      "305/305 [==============================] - 721s 2s/step - loss: 0.6750 - accuracy: 0.5956\n",
      "Epoch 4/5\n",
      "305/305 [==============================] - 626s 2s/step - loss: 0.6752 - accuracy: 0.5956\n",
      "Epoch 5/5\n",
      "305/305 [==============================] - 615s 2s/step - loss: 0.6754 - accuracy: 0.5956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x17d145eca50>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pad or truncate the input sequences\n",
    "# max_sequence_length_x = max(numel(seq) for seq in xtrain[0])  # Assuming 'input_ids' is the first element in xtrain\n",
    "input_length=4096\n",
    "xtrain_padded = pad_sequences(xtrain, maxlen=input_length, padding='post')\n",
    "\n",
    "# Build and compile the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=51000, output_dim=100, input_length=input_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(xtrain_padded, ytrain, epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72212f00-9f96-4ecd-bc2c-2ca62f7b8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model02.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "639657f0-6ae9-4e8b-8bd3-18561ba0f609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12180\n",
      "12180\n"
     ]
    }
   ],
   "source": [
    "print(len(x))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "763ab971-7217-4206-8be0-98690127b632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12180, 4096])\n",
      "(12180,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "db1c4b5d-ebba-41a7-a06e-c33fa66e9bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9744, 4096])\n",
      "(9744,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
