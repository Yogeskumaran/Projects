{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b97c5a99-954a-4943-b377-2a2dafe6152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear Principal,\\n\\nHello! I hope you are havin...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Florida senator,\\n\\nI strongly agree of k...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Senator,\\n\\nPresidential elections are cl...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Mr. Senator, Personal I believe we should...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to the article, \"Driverless Cars Are...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17983</th>\n",
       "      <td>There are many advantages of limiting car usag...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17984</th>\n",
       "      <td>Dear TEACHER_NAME,\\n\\nI think that it is a gre...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17985</th>\n",
       "      <td>It is good to ask for advice from multiple peo...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17986</th>\n",
       "      <td>School is something that almost everyone goes ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17987</th>\n",
       "      <td>Positive Life\\n\\nDo you have gone be positive ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17988 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  generated\n",
       "0      Dear Principal,\\n\\nHello! I hope you are havin...        0.0\n",
       "1      Dear Florida senator,\\n\\nI strongly agree of k...        0.0\n",
       "2      Dear Senator,\\n\\nPresidential elections are cl...        0.0\n",
       "3      Dear Mr. Senator, Personal I believe we should...        0.0\n",
       "4      According to the article, \"Driverless Cars Are...        0.0\n",
       "...                                                  ...        ...\n",
       "17983  There are many advantages of limiting car usag...        0.0\n",
       "17984  Dear TEACHER_NAME,\\n\\nI think that it is a gre...        0.0\n",
       "17985  It is good to ask for advice from multiple peo...        0.0\n",
       "17986  School is something that almost everyone goes ...        0.0\n",
       "17987  Positive Life\\n\\nDo you have gone be positive ...        0.0\n",
       "\n",
       "[17988 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "df=pd.read_csv(r\"B:\\project\\newdataset\\chunk_8.csv\")\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa860b7-78e4-4f0c-836f-ba6ffd299c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "tokenizer=LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "essays=df['text'].tolist()\n",
    "tokens=tokenizer(essays,return_tensors='pt',padding=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c2c56fd-f289-4609-975d-e7115712d642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs size: torch.Size([17988, 1984])\n",
      "Attention Mask size: torch.Size([17988, 1984])\n",
      "Vocabulary Size: 32798\n",
      "Max Sequence Length: 1984\n"
     ]
    }
   ],
   "source": [
    "x=tokens['input_ids']\n",
    "y=df['generated']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "input_ids_size = tokens['input_ids'].size()\n",
    "attention_mask_size = tokens['attention_mask'].size()\n",
    "print(\"Input IDs size:\", input_ids_size)\n",
    "print(\"Attention Mask size:\", attention_mask_size)\n",
    "# Assuming 'tokens' is the result of tokenizer\n",
    "unique_tokens = set(token.item() for seq in tokens['input_ids'] for token in seq)\n",
    "vocabulary_size = len(unique_tokens)\n",
    "\n",
    "print(\"Vocabulary Size:\", vocabulary_size)\n",
    "# Assuming 'input_ids' is the first element in xtrain\n",
    "max_sequence_length_x = max(len(seq) for seq in xtrain)\n",
    "\n",
    "# Print or use the max_sequence_length_x in your pad_sequences and Embedding layer\n",
    "print(\"Max Sequence Length:\", max_sequence_length_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e17c47-d81a-4cd2-969d-c9d9e8a2594b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "450/450 [==============================] - 196s 432ms/step - loss: 0.0116 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "450/450 [==============================] - 203s 451ms/step - loss: 4.0705e-05 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "450/450 [==============================] - 202s 448ms/step - loss: 2.0825e-05 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "450/450 [==============================] - 189s 420ms/step - loss: 1.2665e-05 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "450/450 [==============================] - 192s 426ms/step - loss: 8.1903e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x28ba6781790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "input_length=1984\n",
    "xtrain_np=xtrain.numpy()\n",
    "model.add(Embedding(input_dim=52000,output_dim=100,input_length=input_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_np,ytrain,epochs=5,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7859a3f0-ca95-4e26-ad03-499fcdd4afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 16s 136ms/step - loss: 6.4831e-06 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.48305149297812e-06, 1.0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_np=xtest.numpy()\n",
    "model.evaluate(xtest_np,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a54b157-f1b7-47b6-90db-94bde55724de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"newmodel8.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
