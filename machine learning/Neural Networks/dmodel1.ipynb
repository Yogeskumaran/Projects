{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f8fd302-794e-4da4-8018-60783a69c134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30580, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "filepath=[r\"B:\\project\\human\\human_chunk_1.csv\",r\"B:\\project\\ai\\ai_chunk_1.csv\"]\n",
    "dfs = [pd.read_csv(filepath) for filepath in filepath]\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae1c936-f255-4815-9a7a-ccfc7f3f0510",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import LongformerTokenizer\n",
    "tokenizer=LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
    "essay=df['text'].tolist()\n",
    "tokens=tokenizer(essay,return_tensors='pt',padding=True,truncation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb66d1d8-0197-4210-b7ce-5ed10824dcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs size: torch.Size([30580, 2216])\n",
      "Attention Mask size: torch.Size([30580, 2216])\n",
      "Vocabulary Size: 33991\n"
     ]
    }
   ],
   "source": [
    "x=tokens['input_ids']\n",
    "y=df['generated']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "input_ids_size = tokens['input_ids'].size()\n",
    "attention_mask_size = tokens['attention_mask'].size()\n",
    "print(\"Input IDs size:\", input_ids_size)\n",
    "print(\"Attention Mask size:\", attention_mask_size)\n",
    "# Assuming 'tokens' is the result of tokenizer\n",
    "unique_tokens = set(token.item() for seq in tokens['input_ids'] for token in seq)\n",
    "vocabulary_size = len(unique_tokens)\n",
    "\n",
    "print(\"Vocabulary Size:\", vocabulary_size)\n",
    "# Assuming 'input_ids' is the first element in xtrain\n",
    "max_sequence_length_x = max(len(seq) for seq in xtrain)\n",
    "\n",
    "# Print or use the max_sequence_length_x in your pad_sequences and Embedding layer\n",
    "# print(\"Max Sequence Length:\", max_sequence_length_x)\n",
    "xtrain_np=xtrain.numpy()\n",
    "xtest_np=xtest.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6ab8c5-7cf9-4b60-a299-0732d71321d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From A:\\anaconda\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "383/383 [==============================] - 1027s 3s/step - loss: 0.6935 - accuracy: 0.5012\n",
      "Epoch 2/5\n",
      "383/383 [==============================] - 1104s 3s/step - loss: 0.6933 - accuracy: 0.4947\n",
      "Epoch 3/5\n",
      "383/383 [==============================] - 1102s 3s/step - loss: 0.6932 - accuracy: 0.4989\n",
      "Epoch 4/5\n",
      "383/383 [==============================] - 1189s 3s/step - loss: 0.6932 - accuracy: 0.5026\n",
      "Epoch 5/5\n",
      "383/383 [==============================] - 851s 2s/step - loss: 0.6933 - accuracy: 0.4988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a0f5c79fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "input_length=None\n",
    "xtrain_np=xtrain.numpy()\n",
    "model.add(Embedding(input_dim=52000,output_dim=128,input_length=input_length))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(xtrain_np,ytrain,epochs=5,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41c5b934-f202-4b95-9d8a-d1ec14bac9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "192/192 [==============================] - 46s 238ms/step - loss: 0.6931 - accuracy: 0.5046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6931071877479553, 0.504578173160553]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_np=xtest.numpy()\n",
    "model.evaluate(xtest_np,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0dcea7bc-d673-4619-a7fd-7938c6843a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"dmodel1.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "59c5ede4-ccbb-40a2-ba09-aa101d62db16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 409ms/step\n",
      "0: It is Human-generated text\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "ml = load_model(\"dmodel1.keras\")\n",
    "xnew = \"We accomplish more by doing tasks that we are assigned with to complete We have always get something done if the tasks or assignments are done Take for example people that work jobs day and night they tend to get work or tasks or assignments done How do they get stuff done workers usually plan it out like steps to go though to complete them if they dont follow the steps like how are they going to complete the task or assignment to get it done Workers always need to plan it out before proceeding to the task or assignment to finish or complete For example Generic_Name wants to figure out how to complete his project he need to plan step by step and what materials he needs for the project He follows the step by step plan but realizes what he needs to do later on he gathers the materals and starts to complete his project just by always doing it All of us always have to something to complete any tasks or assignments to finish It s not going to work if we dont always doing something or plan it out it s the reason why if you wanna get it stuff done you have always do it in order complete it For example take school students for a example they tend to always to get work done so they can free time to themselves and usually making sure the answers they write down are correct to get good grades School students have determation to complete classwork they re assigned to so later on they don t have to complete it for homework at home for free time It s better to always complete work so you don t have to complete later on For example any job work usually has work to do like car manufactures they have a assembly to work on because it s where the cars are starting to be made by the workers in the assembly line They have to work the machines to put the parts on the cars that are being work on so it can shipped of to the car dealership Everything revolves around on always getting something on time so it doesn t become a problem later on Everyone like to job workers to school students alwayss have to something its why we tend to get stuff done Always accomplish it by doing it Reasons why we have to do it if we tend to get our task or assignments done then that work doesn t get it the way of what you are trying to on the next task Accomplishing that we are trying to get to is a good way to start off you see like CEOs of a company planning what they want done and to figure it how to accomplish it For example take CEOs they re good at getting stuff done and accomplished it pefectly cause they own businesses and tell his workers what food products or drinks that stores need for people to attract to buy their goods or clothes People always have to plan to work towards to they want to achieve or accomplish even for their future it s not going to work if you don t put the effort into the assignment or tasks to make it happpen You always have to make sure what you want and to make it happen so that your future has more opportuniites In conclusion Always put the effort into it so you can accomplish on any work task assignments that you can achieve later on in your life\"\n",
    "# xnew=\"Studying Science and History at Generic_School offers two very different experiences each with its own advantages Science is a constantly evolving field with new advances and techniques being discovered daily The school provides expert guidance and modern equipment making it an ideal place to explore the complex theories and technologies of the subject In contrast History offers an opportunity to delve into the past and investigate the origins of our civilization and culture Through lectures and field trips Generic_School s expert faculty provides students with a solid foundation of knowledge in the subject while also allowing them to study and discuss unique interpretations of traditional narratives Both Science and History have their advantages but in the end it comes down to each individual student s interests and goals If you are passionate about understanding the complexities of our world then studying Science is the perfect choice If on the other hand you enjoy delving into the past and uncovering the stories of our ancestors then History is the subject for you Whichever path you choose to take the experienced faculty and resources at Generic_School will provide the guidance you need to succeed and make the most of your studies\"\n",
    "# Tokenize the input text\n",
    "xnew_tokens = tokenizer.encode(xnew,truncation=True,padding=True,return_tensors=\"np\")\n",
    "\n",
    "max_sequence_length = 2216\n",
    "xnew_padded = pad_sequences(xnew_tokens, maxlen=max_sequence_length, padding='post', truncating='post')\n",
    "\n",
    "# Use the padded tensor for prediction\n",
    "prediction = ml.predict(xnew_padded)\n",
    "\n",
    "# Set a threshold for classification\n",
    "threshold = 0.5\n",
    "prediction_value = prediction[0, 0]\n",
    "\n",
    "# Check the prediction and print the result\n",
    "if prediction_value >= threshold:\n",
    "    print(\"1: It is an AI-generated text\")\n",
    "else:\n",
    "    print(\"0: It is Human-generated text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a22b1d0-f992-4e2b-94b7-9c40e3889095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text         0\n",
       "generated    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(r\"B:\\project\\ai\\ai_chunk_3.csv\")\n",
    "# essay=data['text'].tolist()\n",
    "# tokens=tokenizer(essay,return_tensors='pt',padding=True,truncation=True)\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54d02123-ae65-491f-b5bd-bf95c288a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokens['input_ids']\n",
    "y=df['generated']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "xtrain_np=xtrain.numpy()\n",
    "xtest_np=xtest.numpy()\n",
    "xtrain_np1=xtrain_np\n",
    "xtest_np1=xtest_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1fe8fdd-67d8-4802-b7e0-b758605b1c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "xtrain_np1 = np.array(xtrain_np1)\n",
    "\n",
    "np.savetxt('B:/project/train/xtrain_np1.csv', xtrain_np1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a673785-d04d-4323-b4a0-d0e6dbe749fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_np1=np.array(xtest_np1)\n",
    "np.savetxt('B:/project/test/xtest_np1.csv', xtest_np1, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72cabae8-b0df-45ef-9a94-5b7f3c8b15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytest.to_csv(\"B:/project/ytest/ytest1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92821198-8b4a-409c-a9f8-e87bf75f9841",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tokens['input_ids']\n",
    "y=df['generated']\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "ytrain.to_csv(\"B:/project/ytrain/ytrain1.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
